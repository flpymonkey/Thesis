{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install wrds\n",
    "# !pip install quantstats\n",
    "# !pip install torch_geometric\n",
    "# !pip install swig\n",
    "# !pip install -q condacolab\n",
    "# !pip install shimmy\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "# !pip install git+https://github.com/flpymonkey/FinRL_Online_Portfolio_Benchmarks.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# from finrl.agents.portfolio_optimization.architectures import EIIE\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (14852, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = '2009-04-01'\n",
    "TRAIN_END_DATE = '2020-12-31'\n",
    "TEST_START_DATE = '2021-01-01'\n",
    "TEST_END_DATE = '2024-01-01'\n",
    "\n",
    "# TRAIN_START_DATE = '2010-01-01'\n",
    "# TRAIN_END_DATE = '2021-10-01'\n",
    "# TEST_START_DATE = '2021-10-01'\n",
    "# TEST_END_DATE = '2023-03-01'\n",
    "\n",
    "TEST_TICKER = [\n",
    "   \"AXP\",\n",
    "    \"AMGN\",\n",
    "    \"AAPL\",\n",
    "    \"BA\",\n",
    "]\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.env_portfolio_optimization.env_portfolio_optimization import PortfolioOptimizationEnv\n",
    "\n",
    "# from finrl.config_tickers import DOW_30_TICKER\n",
    "\n",
    "\n",
    "# # TODO Drop the DOW stock\n",
    "# value_to_remove = \"DOW\"\n",
    "# # Create a new list without the specified string\n",
    "# DOW_30_TICKER = [x for x in DOW_30_TICKER if x != value_to_remove]\n",
    "# print(DOW_30_TICKER)\n",
    "\n",
    "# No time window needed for PPO\n",
    "# TIME_WINDOW = 25\n",
    "COMMISSION_FEE_PERCENT = 0.001\n",
    "INITIAL_CASH = 1000000\n",
    "\n",
    "# TODO try different date ranges\n",
    "# TRAIN_START_DATE = '2009-01-01'\n",
    "# TRAIN_END_DATE = '2018-10-01'\n",
    "# TEST_START_DATE = '2018-10-01'\n",
    "# TEST_END_DATE = '2021-03-01'\n",
    "\n",
    "raw_df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TEST_END_DATE,\n",
    "                     ticker_list = TEST_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date        open        high         low       close     volume  \\\n",
      "0      2009-04-01    3.717500    3.892857    3.710357    3.274470  589372000   \n",
      "1      2009-04-01   48.779999   48.930000   47.099998   34.259613   10850100   \n",
      "2      2009-04-01   13.340000   14.640000   13.080000   11.463929   27701800   \n",
      "3      2009-04-01   34.520000   35.599998   34.209999   26.850752    9288800   \n",
      "4      2009-04-02    3.933571    4.098214    3.920714    3.395579  812366800   \n",
      "...           ...         ...         ...         ...         ...        ...   \n",
      "14847  2023-12-28  261.529999  262.100006  257.679993  260.350006    5096400   \n",
      "14848  2023-12-29  193.899994  194.399994  191.729996  191.591385   42628800   \n",
      "14849  2023-12-29  287.859985  288.489990  286.390015  281.808167    1766600   \n",
      "14850  2023-12-29  187.750000  188.300003  186.529999  185.123352    1913800   \n",
      "14851  2023-12-29  260.670013  262.220001  259.559998  260.660004    3681900   \n",
      "\n",
      "        tic  day  \n",
      "0      AAPL    2  \n",
      "1      AMGN    2  \n",
      "2       AXP    2  \n",
      "3        BA    2  \n",
      "4      AAPL    3  \n",
      "...     ...  ...  \n",
      "14847    BA    3  \n",
      "14848  AAPL    4  \n",
      "14849  AMGN    4  \n",
      "14850   AXP    4  \n",
      "14851    BA    4  \n",
      "\n",
      "[14852 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_df)\n",
    "processed = raw_df\n",
    "\n",
    "assert processed.notnull().all().all(), \"DataFrame contains null values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>0.016610</td>\n",
       "      <td>0.313329</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>0.165873</td>\n",
       "      <td>0.164931</td>\n",
       "      <td>0.162829</td>\n",
       "      <td>0.121385</td>\n",
       "      <td>0.216841</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>0.067544</td>\n",
       "      <td>0.073365</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.059964</td>\n",
       "      <td>0.306650</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>0.077397</td>\n",
       "      <td>0.079819</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.089997</td>\n",
       "      <td>BA</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-04-02</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>0.019902</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.431881</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14847</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>0.586377</td>\n",
       "      <td>0.587655</td>\n",
       "      <td>0.585384</td>\n",
       "      <td>0.605043</td>\n",
       "      <td>0.049378</td>\n",
       "      <td>BA</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14848</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.979194</td>\n",
       "      <td>0.973850</td>\n",
       "      <td>0.973249</td>\n",
       "      <td>0.971834</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.978849</td>\n",
       "      <td>0.972427</td>\n",
       "      <td>0.990078</td>\n",
       "      <td>0.998475</td>\n",
       "      <td>0.035306</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14850</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.950633</td>\n",
       "      <td>0.943623</td>\n",
       "      <td>0.945701</td>\n",
       "      <td>0.968315</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14851</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.584449</td>\n",
       "      <td>0.587924</td>\n",
       "      <td>0.589654</td>\n",
       "      <td>0.605763</td>\n",
       "      <td>0.035673</td>\n",
       "      <td>BA</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14852 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      open      high       low     close    volume   tic  \\\n",
       "0      2009-04-01  0.018773  0.019501  0.018834  0.016610  0.313329  AAPL   \n",
       "1      2009-04-01  0.165873  0.164931  0.162829  0.121385  0.216841  AMGN   \n",
       "2      2009-04-01  0.067544  0.073365  0.066315  0.059964  0.306650   AXP   \n",
       "3      2009-04-01  0.077397  0.079819  0.077716  0.062400  0.089997    BA   \n",
       "4      2009-04-02  0.019865  0.020530  0.019902  0.017224  0.431881  AAPL   \n",
       "...           ...       ...       ...       ...       ...       ...   ...   \n",
       "14847  2023-12-28  0.586377  0.587655  0.585384  0.605043  0.049378    BA   \n",
       "14848  2023-12-29  0.979194  0.973850  0.973249  0.971834  0.022663  AAPL   \n",
       "14849  2023-12-29  0.978849  0.972427  0.990078  0.998475  0.035306  AMGN   \n",
       "14850  2023-12-29  0.950633  0.943623  0.945701  0.968315  0.021185   AXP   \n",
       "14851  2023-12-29  0.584449  0.587924  0.589654  0.605763  0.035673    BA   \n",
       "\n",
       "        day  \n",
       "0      0.50  \n",
       "1      0.50  \n",
       "2      0.50  \n",
       "3      0.50  \n",
       "4      0.75  \n",
       "...     ...  \n",
       "14847  0.75  \n",
       "14848  1.00  \n",
       "14849  1.00  \n",
       "14850  1.00  \n",
       "14851  1.00  \n",
       "\n",
       "[14852 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from finrl.meta.preprocessor.preprocessors import GroupByScaler\n",
    "\n",
    "\n",
    "# TODO - we are using the normalized indicators here, is that okay?\n",
    "\n",
    "\n",
    "portfolio_norm_df = GroupByScaler(by=\"tic\", scaler=MaxAbsScaler).fit_transform(processed)\n",
    "portfolio_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMGN</th>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXP</th>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date  open  high   low  close  volume   day\n",
       "tic                                              \n",
       "AAPL  3713  3713  3713  3713   3713    3713  3713\n",
       "AMGN  3713  3713  3713  3713   3713    3713  3713\n",
       "AXP   3713  3713  3713  3713   3713    3713  3713\n",
       "BA    3713  3713  3713  3713   3713    3713  3713"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_norm_df.groupby(\"tic\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 4\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(portfolio_norm_df.tic.unique())\n",
    "print(f\"Stock Dimension: {stock_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMGN</th>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXP</th>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date  open  high   low  close  volume   day\n",
       "tic                                              \n",
       "AAPL  2960  2960  2960  2960   2960    2960  2960\n",
       "AMGN  2960  2960  2960  2960   2960    2960  2960\n",
       "AXP   2960  2960  2960  2960   2960    2960  2960\n",
       "BA    2960  2960  2960  2960   2960    2960  2960"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = portfolio_norm_df[(portfolio_norm_df[\"date\"] >= TRAIN_START_DATE) & (portfolio_norm_df[\"date\"] <= TRAIN_END_DATE)]\n",
    "df_2021 = portfolio_norm_df[(portfolio_norm_df[\"date\"] >= TEST_START_DATE) & (portfolio_norm_df[\"date\"] <= \"2021-12-31\")]\n",
    "df_2022 = portfolio_norm_df[(portfolio_norm_df[\"date\"] >= \"2022-01-01\") & (portfolio_norm_df[\"date\"] <= \"2022-12-31\")]\n",
    "df_2023 = portfolio_norm_df[(portfolio_norm_df[\"date\"] >= \"2023-01-01\") & (portfolio_norm_df[\"date\"] < TEST_END_DATE)]\n",
    "\n",
    "# TODO use the start and end date here\n",
    "\n",
    "df_train.groupby(\"tic\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO can I used ANOVA, or Analysis of Variance,\n",
    "\n",
    "Compare with ANova,\n",
    "Returns \n",
    "Drawdown period\n",
    "And sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "# from finrl.meta.env_portfolio_optimization.env_portfolio_optimization import PortfolioOptimizationEnv\n",
    "\n",
    "from finrl.agents.portfolio_optimization.models_stable import DRLStableAgent\n",
    "\n",
    "\n",
    "\n",
    "from stable_baselines3.common.logger import configure\n",
    "# Try also training a PPO agent on this same environment\n",
    "\n",
    "\n",
    "environment = PortfolioOptimizationEnv(\n",
    "        df_train,\n",
    "        initial_amount=INITIAL_CASH,\n",
    "        comission_fee_pct=COMMISSION_FEE_PERCENT,\n",
    "        # time_window=TIME_WINDOW,\n",
    "        features=[\"close\", \"high\", \"low\"], # USE THE BETA INDICATOR\n",
    "        normalize_df=None,\n",
    "        reward_scaling=1e-4,\n",
    "    )\n",
    "\n",
    "\n",
    "# TODO figuring out issues with timesteps: https://stackoverflow.com/questions/56700948/understanding-the-total-timesteps-parameter-in-stable-baselines-models\n",
    "\n",
    "agent_ppo = DRLStableAgent(env = environment)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    # \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025, # TODO tried raising the lr which caused vanishing problem\n",
    "    # \"clip_range\": 0.2\n",
    "}\n",
    "\n",
    "# Lower clip_range makes the stocks flatter, very conservative policy\n",
    "\n",
    "# TODO try playing around with the number of epochs? n_epochs\n",
    "# TODO try playing around more with the entropy term, make sure agent does enough exploration during training\n",
    "# TODO try playing around more with the clip papram here\n",
    "\n",
    "\n",
    "model_ppo = agent_ppo.get_model(\"ppo\", device, model_kwargs=PPO_PARAMS, policy_kwargs=None)\n",
    "\n",
    "# set up logger\n",
    "tmp_path = RESULTS_DIR + '/ppo'\n",
    "new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "# Set new logger\n",
    "model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of time steps in an episode:  2960\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 136  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 14   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 408820.4375\n",
      "Final accumulative portfolio value: 0.4088204375\n",
      "Maximum DrawDown: -0.8083675312225344\n",
      "Sharpe ratio: -0.21170600668902145\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -8.9e-05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 143          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050106915 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00624      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.96e-05     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 77668.25\n",
      "Final accumulative portfolio value: 0.07766825\n",
      "Maximum DrawDown: -0.9399716832593044\n",
      "Sharpe ratio: -0.926788838696971\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000172    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 146          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039857905 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00844      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 5.76e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000172   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003772769 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 3.85e-05    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 265771.53125\n",
      "Final accumulative portfolio value: 0.26577153125\n",
      "Maximum DrawDown: -0.8486158709742745\n",
      "Sharpe ratio: -0.4224523144133867\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000159    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045948564 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.05        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0209      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 1.03e-05     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 472902.8548974657\n",
      "Final accumulative portfolio value: 0.4729028548974657\n",
      "Maximum DrawDown: -0.7487799439790471\n",
      "Sharpe ratio: -0.19163428566202811\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.96e+03   |\n",
      "|    ep_rew_mean          | -0.000138  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 144        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00369544 |\n",
      "|    clip_fraction        | 0.0225     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.99      |\n",
      "|    explained_variance   | 0.934      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.00738   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0056    |\n",
      "|    std                  | 0.973      |\n",
      "|    value_loss           | 1.42e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000138   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007155842 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 1.2e-05     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 178707.6875\n",
      "Final accumulative portfolio value: 0.1787076875\n",
      "Maximum DrawDown: -0.9126689786176171\n",
      "Sharpe ratio: -0.5580400650135582\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000145   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005459704 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 4.43e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 232310.40625\n",
      "Final accumulative portfolio value: 0.23231040625\n",
      "Maximum DrawDown: -0.8952473253491672\n",
      "Sharpe ratio: -0.40706904109090697\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000145    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 124          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036574493 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.92        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0196      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 4.77e-06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000145    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 126          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070947274 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.85        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00351     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    std                  | 0.947        |\n",
      "|    value_loss           | 5.16e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 263395.875\n",
      "Final accumulative portfolio value: 0.263395875\n",
      "Maximum DrawDown: -0.857680468245388\n",
      "Sharpe ratio: -0.4317664057051763\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000144   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005800141 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.81       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00822     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 3.54e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 394718.96875\n",
      "Final accumulative portfolio value: 0.39471896875\n",
      "Maximum DrawDown: -0.766579799818201\n",
      "Sharpe ratio: -0.2745243570825825\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000137    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040695453 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.79        |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.000745    |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 2.71e-06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000137    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072554965 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.75        |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.000293    |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    std                  | 0.931        |\n",
      "|    value_loss           | 4.47e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 395775.3125\n",
      "Final accumulative portfolio value: 0.3957753125\n",
      "Maximum DrawDown: -0.7664780802001696\n",
      "Sharpe ratio: -0.232971508613363\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000132   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005185469 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.7        |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00629    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 3.61e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 336513.84375\n",
      "Final accumulative portfolio value: 0.33651384375\n",
      "Maximum DrawDown: -0.8108304063216506\n",
      "Sharpe ratio: -0.31031281871633737\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.00013    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004367332 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.916       |\n",
      "|    value_loss           | 1.15e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 408916.59375\n",
      "Final accumulative portfolio value: 0.40891659375\n",
      "Maximum DrawDown: -0.8197299483156888\n",
      "Sharpe ratio: -0.26839610192110175\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000126   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006359249 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00936    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 3.79e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000126    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062494064 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.66        |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0334      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.916        |\n",
      "|    value_loss           | 3.83e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 445022.34375\n",
      "Final accumulative portfolio value: 0.44502234375\n",
      "Maximum DrawDown: -0.8560087682867825\n",
      "Sharpe ratio: -0.19786944712746374\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000122    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035606371 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.67        |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0182       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.921        |\n",
      "|    value_loss           | 8.86e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 398043.375\n",
      "Final accumulative portfolio value: 0.398043375\n",
      "Maximum DrawDown: -0.804529096880591\n",
      "Sharpe ratio: -0.23003218253169536\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00012     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 301          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064629046 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.66        |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0124      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    std                  | 0.913        |\n",
      "|    value_loss           | 3.69e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.00012    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004623778 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00327     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 2.16e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 850090.5625\n",
      "Final accumulative portfolio value: 0.8500905625\n",
      "Maximum DrawDown: -0.6080013094870664\n",
      "Sharpe ratio: 0.049128041084638405\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.96e+03  |\n",
      "|    ep_rew_mean          | -0.000113 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 129       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 330       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0049758 |\n",
      "|    clip_fraction        | 0.0364    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.59     |\n",
      "|    explained_variance   | 0.665     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0076   |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -0.00439  |\n",
      "|    std                  | 0.902     |\n",
      "|    value_loss           | 1.3e-06   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 379991.1875\n",
      "Final accumulative portfolio value: 0.3799911875\n",
      "Maximum DrawDown: -0.8012456099471295\n",
      "Sharpe ratio: -0.2794920884724948\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000112    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 346          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042276923 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.58        |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00826     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.904        |\n",
      "|    value_loss           | 3.32e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000112   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006824593 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.57       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 4.46e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 256929.078125\n",
      "Final accumulative portfolio value: 0.256929078125\n",
      "Maximum DrawDown: -0.8602758272758305\n",
      "Sharpe ratio: -0.4127385209089822\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000113    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073242933 |\n",
      "|    clip_fraction        | 0.0748       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.55        |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00408     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    std                  | 0.897        |\n",
      "|    value_loss           | 7.46e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 349300.8125\n",
      "Final accumulative portfolio value: 0.3493008125\n",
      "Maximum DrawDown: -0.8333432869090829\n",
      "Sharpe ratio: -0.30448504362112877\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000113   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006121346 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.57       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0101      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.904       |\n",
      "|    value_loss           | 2.25e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000113    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 404          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059781307 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.56        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00222     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 2.17e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 657374.5\n",
      "Final accumulative portfolio value: 0.6573745\n",
      "Maximum DrawDown: -0.7781210229482672\n",
      "Sharpe ratio: -0.018226490569423378\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000109   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007133199 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.54       |\n",
      "|    explained_variance   | 0.0655      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 3.27e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 453776.25\n",
      "Final accumulative portfolio value: 0.45377625\n",
      "Maximum DrawDown: -0.7631821965617167\n",
      "Sharpe ratio: -0.16665091774719698\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000107   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 435         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007482495 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.54       |\n",
      "|    explained_variance   | -0.434      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00262    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 5.76e-07    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 453131.5625\n",
      "Final accumulative portfolio value: 0.4531315625\n",
      "Maximum DrawDown: -0.8311333976111593\n",
      "Sharpe ratio: -0.17134577344701113\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000106    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 450          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068636783 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.53        |\n",
      "|    explained_variance   | -0.941       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00553      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 4.26e-06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000106    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 132          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 463          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052670673 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.54        |\n",
      "|    explained_variance   | -1.32        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00976     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    std                  | 0.898        |\n",
      "|    value_loss           | 1.17e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 327692.46875\n",
      "Final accumulative portfolio value: 0.32769246875\n",
      "Maximum DrawDown: -0.8587711802215863\n",
      "Sharpe ratio: -0.3009474790325136\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000106    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 132          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 478          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064454274 |\n",
      "|    clip_fraction        | 0.0609       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.55        |\n",
      "|    explained_variance   | -0.366       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0103      |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    std                  | 0.898        |\n",
      "|    value_loss           | 3.41e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 394952.9375\n",
      "Final accumulative portfolio value: 0.3949529375\n",
      "Maximum DrawDown: -0.8039707647556931\n",
      "Sharpe ratio: -0.22924102421570933\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000106   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 493         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005622694 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.56       |\n",
      "|    explained_variance   | -0.793      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00453    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    std                  | 0.899       |\n",
      "|    value_loss           | 2.6e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000106   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006200097 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.58       |\n",
      "|    explained_variance   | -1.51       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 1.51e-05    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 712950.3125\n",
      "Final accumulative portfolio value: 0.7129503125\n",
      "Maximum DrawDown: -0.8246481484315716\n",
      "Sharpe ratio: 0.013853916771306214\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000102    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 521          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036436939 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.61        |\n",
      "|    explained_variance   | -0.0388      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00654      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    std                  | 0.91         |\n",
      "|    value_loss           | 3.78e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 193820.65625\n",
      "Final accumulative portfolio value: 0.19382065625\n",
      "Maximum DrawDown: -0.8683701714663599\n",
      "Sharpe ratio: -0.5115404170440574\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000105   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004097686 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | 0.0608      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00507     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 5.77e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000105   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006594265 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.0837      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0217     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 6.25e-07    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 180102.015625\n",
      "Final accumulative portfolio value: 0.180102015625\n",
      "Maximum DrawDown: -0.8796563495212099\n",
      "Sharpe ratio: -0.5271660021594948\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000108    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 562          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066230395 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.59        |\n",
      "|    explained_variance   | 0.0914       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0277      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    std                  | 0.9          |\n",
      "|    value_loss           | 3.22e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 368761.0625\n",
      "Final accumulative portfolio value: 0.3687610625\n",
      "Maximum DrawDown: -0.8445115970742609\n",
      "Sharpe ratio: -0.2485747066112179\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000107    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 577          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063029565 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.56        |\n",
      "|    explained_variance   | -0.432       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0253      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    std                  | 0.899        |\n",
      "|    value_loss           | 5.32e-07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000107   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005109215 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.56       |\n",
      "|    explained_variance   | -0.343      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 1.29e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 236900.125\n",
      "Final accumulative portfolio value: 0.236900125\n",
      "Maximum DrawDown: -0.8635877623587347\n",
      "Sharpe ratio: -0.43230439680324356\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000109   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007429989 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.56       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00748    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 4.04e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 523264.90625\n",
      "Final accumulative portfolio value: 0.52326490625\n",
      "Maximum DrawDown: -0.7889323660224923\n",
      "Sharpe ratio: -0.1384089604594755\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000107   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 625         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006533456 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.55       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    std                  | 0.897       |\n",
      "|    value_loss           | 2.54e-07    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 219097.71875\n",
      "Final accumulative portfolio value: 0.21909771875\n",
      "Maximum DrawDown: -0.9091372596807141\n",
      "Sharpe ratio: -0.44890961123814416\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000109    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 641          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052610696 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.55        |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0101      |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.897        |\n",
      "|    value_loss           | 5.62e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000109    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 653          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071541886 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.57        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0172       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    std                  | 0.903        |\n",
      "|    value_loss           | 8.75e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 208040.9375\n",
      "Final accumulative portfolio value: 0.2080409375\n",
      "Maximum DrawDown: -0.915334617863351\n",
      "Sharpe ratio: -0.43344177139400003\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00011     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 667          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069906795 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.55        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00627     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 9.18e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 384864.5625\n",
      "Final accumulative portfolio value: 0.3848645625\n",
      "Maximum DrawDown: -0.822832725886605\n",
      "Sharpe ratio: -0.25683492366730915\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.00011    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008245644 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.53       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 8.15e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.00011    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007955322 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.52       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00235     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    std                  | 0.89        |\n",
      "|    value_loss           | 5.98e-06    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 435215.25\n",
      "Final accumulative portfolio value: 0.43521525\n",
      "Maximum DrawDown: -0.8093200783520083\n",
      "Sharpe ratio: -0.18330381644095914\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000109   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006803118 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.52       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 3.48e-07    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 212130.83116857483\n",
      "Final accumulative portfolio value: 0.21213083116857484\n",
      "Maximum DrawDown: -0.8751917967219094\n",
      "Sharpe ratio: -0.4803858346883751\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00011     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 727          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072501753 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.52        |\n",
      "|    explained_variance   | -0.156       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0012      |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 3.72e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00011     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 741          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063780984 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.51        |\n",
      "|    explained_variance   | -0.793       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00125      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 7.65e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 394103.0\n",
      "Final accumulative portfolio value: 0.394103\n",
      "Maximum DrawDown: -0.7254643869715531\n",
      "Sharpe ratio: -0.26653294802590644\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00011     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 758          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072803893 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.5         |\n",
      "|    explained_variance   | -0.871       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00139     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    std                  | 0.886        |\n",
      "|    value_loss           | 5.74e-07     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 227923.05817259446\n",
      "Final accumulative portfolio value: 0.22792305817259448\n",
      "Maximum DrawDown: -0.8451591465140287\n",
      "Sharpe ratio: -0.44670104237224567\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000111   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006450204 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.49       |\n",
      "|    explained_variance   | -0.509      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 2.55e-07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000111    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 788          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063243713 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.51        |\n",
      "|    explained_variance   | -0.317       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0457       |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 1.41e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 170341.375\n",
      "Final accumulative portfolio value: 0.170341375\n",
      "Maximum DrawDown: -0.8905012985659407\n",
      "Sharpe ratio: -0.5981141148169019\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.000113    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 804          |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066911886 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.53        |\n",
      "|    explained_variance   | -0.208       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00329     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 5.14e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 701738.0625\n",
      "Final accumulative portfolio value: 0.7017380625\n",
      "Maximum DrawDown: -0.6656510558543363\n",
      "Sharpe ratio: -0.022638672190328616\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000111   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 820         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006424481 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.51       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00937    |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.885       |\n",
      "|    value_loss           | 7.07e-08    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 431358.65625\n",
      "Final accumulative portfolio value: 0.43135865625\n",
      "Maximum DrawDown: -0.8245707024731501\n",
      "Sharpe ratio: -0.23143857716630503\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00011     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 836          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081108995 |\n",
      "|    clip_fraction        | 0.0683       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.49        |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0207      |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    std                  | 0.889        |\n",
      "|    value_loss           | 3.26e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00011     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 850          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070521063 |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.51        |\n",
      "|    explained_variance   | -0.831       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0359      |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 1.61e-06     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 212844.203125\n",
      "Final accumulative portfolio value: 0.212844203125\n",
      "Maximum DrawDown: -0.8884865410551601\n",
      "Sharpe ratio: -0.41918554472133085\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | -0.000111   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 866         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006943336 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.51       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00965    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    std                  | 0.892       |\n",
      "|    value_loss           | 5.99e-08    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 470397.1875\n",
      "Final accumulative portfolio value: 0.4703971875\n",
      "Maximum DrawDown: -0.7843586292583283\n",
      "Sharpe ratio: -0.19534966248901697\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.96e+03     |\n",
      "|    ep_rew_mean          | -0.00011     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 882          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069375043 |\n",
      "|    clip_fraction        | 0.0567       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.52        |\n",
      "|    explained_variance   | -0.896       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0106       |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 2.81e-07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Once optimal policy is learned it shouldnt be stochastic, giventhe state\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# TODO see graphs below, need to have the correct number of timestemps and add epochs\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model_ppo \u001b[38;5;241m=\u001b[39m \u001b[43mDRLStableAgent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ppo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TRAINED_MODEL_DIR\n\u001b[0;32m      8\u001b[0m model_ppo\u001b[38;5;241m.\u001b[39msave(TRAINED_MODEL_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/agent_opt_ppo_update\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\finrl\\agents\\portfolio_optimization\\models_stable.py:79\u001b[0m, in \u001b[0;36mDRLStableAgent.train_model\u001b[1;34m(model, env, episodes)\u001b[0m\n\u001b[0;32m     75\u001b[0m max_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(env\u001b[38;5;241m.\u001b[39m_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax number of time steps in an episode: \u001b[39m\u001b[38;5;124m\"\u001b[39m, max_steps)\n\u001b[1;32m---> 79\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# TODO fix this\u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:313\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\stable_baselines3\\ppo\\ppo.py:279\u001b[0m, in \u001b[0;36mPPO.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Optimization step\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 279\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[0;32m    281\u001b[0m th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Once optimal policy is learned it shouldnt be stochastic, giventhe state\n",
    "\n",
    "# TODO see graphs below, need to have the correct number of timestemps and add epochs\n",
    "model_ppo = DRLStableAgent.train_model(model_ppo, env=environment, episodes=50)\n",
    "\n",
    "from finrl.config import TRAINED_MODEL_DIR\n",
    "\n",
    "model_ppo.save(TRAINED_MODEL_DIR + \"/agent_opt_ppo_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_2021.index.unique()) - 1)\n",
    "print(df_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_results = {\n",
    "    \"date\": environment._terminal_date_memory,\n",
    "    \"training\": environment._terminal_asset_memory[\"final\"],\n",
    "    \"2021\": {},\n",
    "    \"2022\": {},\n",
    "    \"2023\": {}\n",
    "}\n",
    "\n",
    "\n",
    "environment_2021 = PortfolioOptimizationEnv(\n",
    "    df_2021,\n",
    "    initial_amount=INITIAL_CASH,\n",
    "    comission_fee_pct=COMMISSION_FEE_PERCENT,\n",
    "    # time_window=TIME_WINDOW,\n",
    "    features=[\"close\", \"high\", \"low\"],\n",
    "    normalize_df=None,\n",
    "        reward_scaling=1e-4,\n",
    ")\n",
    "\n",
    "\n",
    "environment_2022 = PortfolioOptimizationEnv(\n",
    "    df_2022,\n",
    "    initial_amount=INITIAL_CASH,\n",
    "    comission_fee_pct=COMMISSION_FEE_PERCENT,\n",
    "    # time_window=TIME_WINDOW,\n",
    "    features=[\"close\", \"high\", \"low\"],\n",
    "    normalize_df=None,\n",
    "        reward_scaling=1e-4,\n",
    ")\n",
    "\n",
    "environment_2023 = PortfolioOptimizationEnv(\n",
    "    df_2023,\n",
    "    initial_amount=INITIAL_CASH,\n",
    "    comission_fee_pct=COMMISSION_FEE_PERCENT,\n",
    "    # time_window=TIME_WINDOW,\n",
    "    features=[\"close\", \"high\", \"low\"],\n",
    "    normalize_df=None,\n",
    "        reward_scaling=1e-4,\n",
    ")\n",
    "\n",
    "\n",
    "print(model_ppo._num_timesteps_at_start)\n",
    "\n",
    "# 2021\n",
    "values, dates = DRLStableAgent.DRL_prediction(model_ppo, environment_2021)\n",
    "PPO_results[\"2021\"][\"value\"] = environment_2021._terminal_asset_memory[\"final\"]\n",
    "PPO_results[\"2021\"][\"date\"] = environment_2021._terminal_date_memory\n",
    "\n",
    "\n",
    "# 2022\n",
    "values, dates = DRLStableAgent.DRL_prediction(model_ppo, environment_2022)\n",
    "PPO_results[\"2022\"][\"value\"] = environment_2022._terminal_asset_memory[\"final\"]\n",
    "PPO_results[\"2022\"][\"date\"] = environment_2022._terminal_date_memory\n",
    "\n",
    "# # 2023\n",
    "# DRLStableAgent.DRL_prediction(model_ppo, environment_2023)\n",
    "# PPO_results[\"2023\"][\"value\"] = environment_2023._asset_memory[\"final\"]\n",
    "# PPO_results[\"2023\"][\"date\"] = environment_2023._date_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_2021['date'].unique()) - 1)\n",
    "\n",
    "print(len(PPO_results['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.plot(PPO_results[\"date\"], PPO_results[\"training\"], label=\"PPO\")\n",
    "\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.title(\"Performance in training period\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UBAH_results = {\n",
    "    \"train\": {},\n",
    "    \"2021\": {},\n",
    "    \"2022\": {},\n",
    "    \"2023\": {},\n",
    "}\n",
    "\n",
    "PORTFOLIO_SIZE = len(DOW_30_TICKER)\n",
    "\n",
    "\n",
    "\n",
    "# This is the CRP strategy NOT Buy and hold \n",
    "# train period\n",
    "terminated = False\n",
    "environment.reset()\n",
    "while not terminated:\n",
    "    action = [0] + [1/PORTFOLIO_SIZE] * PORTFOLIO_SIZE\n",
    "    _, _, terminated, _ = environment.step(action)\n",
    "UBAH_results[\"train\"][\"value\"] = environment._terminal_asset_memory[\"final\"]\n",
    "UBAH_results[\"train\"][\"date\"] = environment._terminal_date_memory\n",
    "\n",
    "# 2021\n",
    "terminated = False\n",
    "environment_2021.reset()\n",
    "while not terminated:\n",
    "    action = [0] + [1/PORTFOLIO_SIZE] * PORTFOLIO_SIZE\n",
    "    _, _, terminated, _ = environment_2021.step(action)\n",
    "UBAH_results[\"2021\"][\"value\"] = environment_2021._terminal_asset_memory[\"final\"]\n",
    "UBAH_results[\"2021\"][\"date\"] = environment_2021._terminal_date_memory\n",
    "\n",
    "# 2022\n",
    "terminated = False\n",
    "environment_2022.reset()\n",
    "while not terminated:\n",
    "    action = [0] + [1/PORTFOLIO_SIZE] * PORTFOLIO_SIZE\n",
    "    _, _, terminated, _ = environment_2022.step(action)\n",
    "UBAH_results[\"2022\"][\"value\"] = environment_2022._terminal_asset_memory[\"final\"]\n",
    "UBAH_results[\"2022\"][\"date\"] = environment_2022._terminal_date_memory\n",
    "\n",
    "# # 2023\n",
    "# terminated = False\n",
    "# environment_2023.reset()\n",
    "# while not terminated:\n",
    "#     action = [0] + [1/PORTFOLIO_SIZE] * PORTFOLIO_SIZE\n",
    "#     _, _, terminated, _ = environment_2023.step(action)\n",
    "# UBAH_results[\"2023\"][\"value\"] = environment_2023._terminal_asset_memory[\"final\"]\n",
    "# UBAH_results[\"2023\"][\"date\"] = environment_2023._terminal_date_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.plot(UBAH_results[\"train\"][\"date\"], UBAH_results[\"train\"][\"value\"], label=\"Buy and Hold\")\n",
    "plt.plot(PPO_results[\"date\"], PPO_results[\"training\"], label=\"PPO\")\n",
    "\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.title(\"Performance in training period\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(UBAH_results[\"2021\"][\"date\"], UBAH_results[\"2021\"][\"value\"], label=\"Buy and Hold\")\n",
    "plt.plot(PPO_results[\"2021\"][\"date\"], PPO_results[\"2021\"][\"value\"], label=\"PPO\")\n",
    "\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.title(\"Performance in 2021\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(UBAH_results[\"2022\"][\"date\"], UBAH_results[\"2022\"][\"value\"], label=\"Buy and Hold\")\n",
    "plt.plot(PPO_results[\"2022\"][\"date\"], PPO_results[\"2022\"][\"value\"], label=\"PPO\")\n",
    "\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.title(\"Performance in 2022\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(UBAH_results[\"2023\"][\"date\"], UBAH_results[\"2023\"][\"value\"], label=\"Buy and Hold\")\n",
    "# plt.plot(PPO_results[\"2023\"][\"date\"], PPO_results[\"2023\"][\"value\"], label=\"PPO\")\n",
    "\n",
    "# plt.xlabel(\"Days\")\n",
    "# plt.ylabel(\"Portfolio Value\")\n",
    "# plt.title(\"Performance in 2023\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.make_archive('train', 'zip', '../content')\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download(\"train.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
